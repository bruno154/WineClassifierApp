{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando Padrões em texto com Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"nCoV_tweets.csv\", index_col=0, parse_dates=['dt'])\n",
    "docs = [\"curso de data, DATA science\", \"tutorial de data analysis\", \"não sei mais o que escrever\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>analysis</th>\n",
       "      <th>curso</th>\n",
       "      <th>data</th>\n",
       "      <th>escrever</th>\n",
       "      <th>mais</th>\n",
       "      <th>não</th>\n",
       "      <th>science</th>\n",
       "      <th>sei</th>\n",
       "      <th>tutorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>curso de data, DATA science</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tutorial de data analysis</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>não sei mais o que escrever</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             DATA  analysis  curso  data  escrever  mais  não  \\\n",
       "curso de data, DATA science     1         0      1     1         0     0    0   \n",
       "tutorial de data analysis       0         1      0     1         0     0    0   \n",
       "não sei mais o que escrever     0         0      0     0         1     1    1   \n",
       "\n",
       "                             science  sei  tutorial  \n",
       "curso de data, DATA science        1    0         0  \n",
       "tutorial de data analysis          0    0         1  \n",
       "não sei mais o que escrever        0    1         0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_transformer = CountVectorizer(binary = False ,analyzer='word', lowercase=False, stop_words=['de','que'], ngram_range=(1,1), min_df=1)\n",
    "mx = bag_of_words_transformer.fit_transform(docs).todense()\n",
    "terms = bag_of_words_transformer.get_feature_names()\n",
    "pd.DataFrame(mx, columns=terms, index=docs)\n",
    "\n",
    "\n",
    "#lowercase\n",
    "#analyzer='char'\n",
    "#strip_accents = 'unicode'\n",
    "#binary = True\n",
    "\n",
    "#stop_words=['de']\n",
    "#ngram_range=(1,1)   unigrama,bigrama, trigrama\n",
    "#min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>curso</th>\n",
       "      <th>data</th>\n",
       "      <th>de</th>\n",
       "      <th>escrever</th>\n",
       "      <th>mais</th>\n",
       "      <th>não</th>\n",
       "      <th>que</th>\n",
       "      <th>science</th>\n",
       "      <th>sei</th>\n",
       "      <th>tutorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>curso de data, DATA science</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tutorial de data analysis</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>não sei mais o que escrever</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             analysis  curso  data    de  escrever  mais  não  \\\n",
       "curso de data, DATA science      0.00    0.2  0.40  0.20       0.0   0.0  0.0   \n",
       "tutorial de data analysis        0.25    0.0  0.25  0.25       0.0   0.0  0.0   \n",
       "não sei mais o que escrever      0.00    0.0  0.00  0.00       0.2   0.2  0.2   \n",
       "\n",
       "                             que  science  sei  tutorial  \n",
       "curso de data, DATA science  0.0      0.2  0.0      0.00  \n",
       "tutorial de data analysis    0.0      0.0  0.0      0.25  \n",
       "não sei mais o que escrever  0.2      0.0  0.2      0.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matriz de frequencia de palavras\n",
    "# tf-idf ~= frequencia da palavra no documento * inverso da frequencia da palavra em todos os documentos\n",
    "bag_of_words_transformer = TfidfVectorizer(use_idf=False,norm='l1')\n",
    "mx = bag_of_words_transformer.fit_transform(docs).todense()\n",
    "terms= bag_of_words_transformer.get_feature_names()\n",
    "pd.DataFrame(mx, columns=terms, index=docs)\n",
    "\n",
    "\n",
    "#norm = Each output row will have unit norm, either: * 'l2' Sum of squares of vector elements is 1\n",
    "#The consine similarity between two vectors is their dot product when l2 norm has been applied.\n",
    "#* 'l1': Sum of absolute values of vector elements is 1. See proporcessing.normalize\n",
    "\n",
    "#use_idf = False\n",
    "#use_idf = False e norm = l1, frequencia simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('analis', 'analis')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(language='portuguese')\n",
    "stemmer.stem(\"analisado\"), stemmer.stem(\"analise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6706, 618)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_transformer = CountVectorizer(min_df=4, stop_words='english', ngram_range=(3,3))\n",
    "mx1 = bag_of_words_transformer.fit_transform(tweets['txt'])#to.dense()\n",
    "mx1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 - Silhoutte: 0.7745554448279538\n",
      "k = 3 - Silhoutte: 0.7512903428233243\n",
      "k = 4 - Silhoutte: 0.7909093389391644\n",
      "k = 5 - Silhoutte: 0.7855735812615643\n",
      "k = 6 - Silhoutte: 0.7865938949670536\n",
      "k = 7 - Silhoutte: 0.7944573862250106\n",
      "k = 8 - Silhoutte: 0.794740266937335\n",
      "k = 9 - Silhoutte: 0.7105856322546324\n"
     ]
    }
   ],
   "source": [
    "for k in range(2,10):\n",
    "    cluster = make_pipeline(MaxAbsScaler(),  KMeans(n_clusters=k, random_state=0))\n",
    "    cluster.fit(mx1)\n",
    "    p= cluster.predict(mx1)\n",
    "    \n",
    "    sil = silhouette_score(mx1, p)\n",
    "    print(f\"k = {k} - Silhoutte: {sil}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = bag_of_words_transformer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 - Size 6466\n",
      "confirmed cases coronavirus              0.002011\n",
      "coronavirus death toll                   0.002165\n",
      "30 hours birth                           0.002320\n",
      "accidentally leaked real                 0.002474\n",
      "tencent accidentally leaked              0.002629\n",
      "just 30 hours                            0.002784\n",
      "zhuang bing du                           0.002938\n",
      "novel coronavirus 2019                   0.002938\n",
      "guan zhuang bing                         0.002938\n",
      "cruise ship japan                        0.003093\n",
      "2019 novel coronavirus                   0.003248\n",
      "news china coronavirus                   0.003402\n",
      "world health organization                0.003712\n",
      "coronaoutbreak coronanews ncov2019       0.004176\n",
      "coronavirus coronaoutbreak coronanews    0.004176\n",
      "coronavirus asiannetwalking https        0.004330\n",
      "health coronavirus asiannetwalking       0.004330\n",
      "coronavirus 2019 ncov                    0.005104\n",
      "amid coronavirus outbreak                0.005104\n",
      "coronavirus outbreak https               0.007423\n",
      "dtype: float64\n",
      "\n",
      "Cluster 1 - Size 13\n",
      "coronavirus survive details                   0.0\n",
      "coronavirus transmitted people                0.0\n",
      "coronavirus travel ban                        0.0\n",
      "coronavirus update china                      0.0\n",
      "coronavirus updates live                      0.0\n",
      "coronavirus vaccine breakthrough              0.0\n",
      "coronaviruswuhan coronavirusoutbreak https    0.0\n",
      "zone china sure                               0.0\n",
      "coronavirus vaccine https                     0.0\n",
      "coronavirus wuhan 2019ncov                    0.0\n",
      "coronavirus wuhan https                       0.0\n",
      "coronavirus wuhancoronavirus wuhanvirus       0.0\n",
      "coronavirusoutbreak coronavirus https         0.0\n",
      "wuhan coronavirusoutbreak china               1.0\n",
      "china coronavirus prayforwuhan                1.0\n",
      "prayforwuhan coronavirus https                1.0\n",
      "coronavirus update wuhan                      1.0\n",
      "coronavirusoutbreak china coronavirus         1.0\n",
      "coronavirus prayforwuhan coronavirus          1.0\n",
      "update wuhan coronavirusoutbreak              1.0\n",
      "dtype: float64\n",
      "\n",
      "Cluster 2 - Size 12\n",
      "https qvezftkwkq https    0.166667\n",
      "gt https bluksptnnq       0.166667\n",
      "n8owlcko0x virus https    0.166667\n",
      "https n8owlcko0x virus    0.166667\n",
      "gt https n8owlcko0x       0.166667\n",
      "9orx4j6buu virus https    0.250000\n",
      "survive details gt        0.250000\n",
      "gt https 9orx4j6buu       0.250000\n",
      "https 9orx4j6buu virus    0.250000\n",
      "virus update details      0.666667\n",
      "update details gt         0.666667\n",
      "diagnostic kits virus     1.000000\n",
      "wuhan test lab            1.000000\n",
      "cdc ships diagnostic      1.000000\n",
      "ships diagnostic kits     1.000000\n",
      "test lab opens            1.000000\n",
      "lab opens cdc             1.000000\n",
      "details gt https          1.000000\n",
      "kits virus update         1.000000\n",
      "opens cdc ships           1.000000\n",
      "dtype: float64\n",
      "\n",
      "Cluster 3 - Size 168\n",
      "https qvezftkwkq virus           0.065476\n",
      "sars flu https                   0.065476\n",
      "questions outbreak answered      0.083333\n",
      "virus coronavirus https          0.083333\n",
      "coronavirus biggest questions    0.083333\n",
      "https efzbdv4cot details         0.083333\n",
      "biggest questions outbreak       0.083333\n",
      "efzbdv4cot details gt            0.083333\n",
      "n8owlcko0x virus https           0.089286\n",
      "https 9orx4j6buu https           0.095238\n",
      "gt https qvezftkwkq              0.101190\n",
      "coronavirus sars flu             0.119048\n",
      "9orx4j6buu virus https           0.125000\n",
      "https n8owlcko0x virus           0.142857\n",
      "virus coronavirus sars           0.160714\n",
      "https 9orx4j6buu virus           0.178571\n",
      "gt https n8owlcko0x              0.196429\n",
      "survive details gt               0.255952\n",
      "gt https 9orx4j6buu              0.273810\n",
      "details gt https                 1.000000\n",
      "dtype: float64\n",
      "\n",
      "Cluster 4 - Size 7\n",
      "coronavirus update china                      0.000000\n",
      "coronavirus update wuhan                      0.000000\n",
      "coronavirus vaccine breakthrough              0.000000\n",
      "coronaviruswuhan coronavirusoutbreak https    0.000000\n",
      "coronavirus wuhan 2019ncov                    0.000000\n",
      "zone china sure                               0.000000\n",
      "coronavirus wuhan https                       0.000000\n",
      "coronavirus wuhancoronavirus wuhanvirus       0.000000\n",
      "coronavirusoutbreak china coronavirus         0.000000\n",
      "coronavirusoutbreak coronavirus https         0.000000\n",
      "coronavirusoutbreak safety tips               0.000000\n",
      "rate recovery rate                            0.714286\n",
      "fully automated live                          0.857143\n",
      "mortality rate recovery                       0.857143\n",
      "automated live coronavirus                    0.857143\n",
      "live statistics mortality                     1.000000\n",
      "coronavirus updates live                      1.000000\n",
      "updates live statistics                       1.000000\n",
      "statistics mortality rate                     1.000000\n",
      "live coronavirus updates                      1.000000\n",
      "dtype: float64\n",
      "\n",
      "Cluster 5 - Size 18\n",
      "coronavirus survive details                0.000000\n",
      "coronavirus transmitted people             0.000000\n",
      "coronavirus travel ban                     0.000000\n",
      "coronavirusoutbreak coronavirus https      0.000000\n",
      "coronavirus update wuhan                   0.000000\n",
      "coronavirus update china                   0.000000\n",
      "coronavirus vaccine breakthrough           0.000000\n",
      "coronavirus vaccine https                  0.000000\n",
      "coronavirus wuhan 2019ncov                 0.000000\n",
      "coronavirus wuhan https                    0.000000\n",
      "coronavirus wuhancoronavirus wuhanvirus    0.000000\n",
      "coronavirus updates live                   0.000000\n",
      "zone china sure                            0.000000\n",
      "whatsapp 0555171905 https                  0.777778\n",
      "days vals surprise                         0.777778\n",
      "0205414305or whatsapp 0555171905           0.944444\n",
      "reach 0205414305or whatsapp                1.000000\n",
      "special reach 0205414305or                 1.000000\n",
      "surprise special reach                     1.000000\n",
      "vals surprise special                      1.000000\n",
      "dtype: float64\n",
      "\n",
      "Cluster 6 - Size 8\n",
      "coronavirus update wuhan                   0.000\n",
      "coronavirusoutbreak coronavirus https      0.000\n",
      "coronavirus updates live                   0.000\n",
      "zone china sure                            0.000\n",
      "coronavirus vaccine breakthrough           0.000\n",
      "coronavirus vaccine https                  0.000\n",
      "coronavirus wuhan 2019ncov                 0.000\n",
      "coronavirus wuhan https                    0.000\n",
      "coronavirus wuhancoronavirus wuhanvirus    0.000\n",
      "https efzbdv4cot details                   0.125\n",
      "survive details gt                         0.125\n",
      "details gt https                           0.250\n",
      "stranded hannaziady cnnbusiness            0.625\n",
      "getting stranded hannaziady                0.625\n",
      "hannaziady cnnbusiness https               0.625\n",
      "coronavirus goods getting                  1.000\n",
      "global shipping hit                        1.000\n",
      "hit coronavirus goods                      1.000\n",
      "shipping hit coronavirus                   1.000\n",
      "goods getting stranded                     1.000\n",
      "dtype: float64\n",
      "\n",
      "Cluster 7 - Size 14\n",
      "coronavirus survive details         0.0\n",
      "coronavirus wuhan https             0.0\n",
      "coronavirus wuhan 2019ncov          0.0\n",
      "coronavirus vaccine https           0.0\n",
      "coronavirus vaccine breakthrough    0.0\n",
      "coronavirus updates live            0.0\n",
      "coronavirusoutbreak safety tips     0.0\n",
      "coronavirus transmitted people      0.0\n",
      "coronavirus travel ban              0.0\n",
      "coronavirus update china            0.0\n",
      "year old woman                      1.0\n",
      "woman 15th person                   1.0\n",
      "coronavirus fifth queensland        1.0\n",
      "37 year old                         1.0\n",
      "diagnosed coronavirus fifth         1.0\n",
      "person australia diagnosed          1.0\n",
      "15th person australia               1.0\n",
      "australia diagnosed coronavirus     1.0\n",
      "fifth queensland https              1.0\n",
      "old woman 15th                      1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "k=8\n",
    "cluster = make_pipeline(MaxAbsScaler(), KMeans(n_clusters=k, random_state=0))\n",
    "cluster.fit(mx1)\n",
    "p = cluster.predict(mx1)\n",
    "\n",
    "for c in np.unique(p):\n",
    "    print(f'\\nCluster {c} - Size {(p == c).sum()}')\n",
    "    rank = pd.Series(np.array(mx1[p==c].mean(axis=0)).squeeze(), index=terms).sort_values().tail(20)\n",
    "    print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02523771, 2.64575131, 3.22102468, ..., 2.47019268, 2.50312305,\n",
       "        3.16227766],\n",
       "       [0.02523771, 2.64575131, 3.22102468, ..., 2.47019268, 2.50312305,\n",
       "        3.16227766],\n",
       "       [0.02523771, 2.64575131, 3.22102468, ..., 2.47019268, 2.50312305,\n",
       "        3.16227766],\n",
       "       ...,\n",
       "       [1.73035876, 3.16227766, 3.65718471, ..., 3.01692755, 3.04394892,\n",
       "        3.60555128],\n",
       "       [0.02523771, 2.64575131, 3.22102468, ..., 2.47019268, 2.50312305,\n",
       "        3.16227766],\n",
       "       [0.02523771, 2.64575131, 3.22102468, ..., 2.47019268, 2.50312305,\n",
       "        3.16227766]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.transform(mx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLuster 0 = what the actual -\n",
      "\n",
      "CLuster 1 =  Coronavirus-Update !!#Wuhan #CoronavirusOutbreak #China #Coronavirus #PrayForWuhan #coronavirus... https://t.co/z183aeekZN\n",
      "\n",
      "CLuster 2 = Wuhan Test Lab Opens; CDC Ships Diagnostic Kits: Virus Update SEE DETAILS AT ==&gt; https://t.co/n8oWlcKo0x #virus... https://t.co/7slO1kBzPw\n",
      "\n",
      "CLuster 3 = Coronavirus Latest Updates: Everything You Need to Know SEE DETAILS AT ==&gt; https://t.co/9orX4j6BuU #virus... https://t.co/EZkVAQuI3G\n",
      "\n",
      "CLuster 4 = @ABSCBNNews @raphbosano Fully Automated Live #CoronaVirus Updates. \n",
      "* Live Statistics: Mortality rate, recovery rat... https://t.co/RXbHWuWM58\n",
      "\n",
      "CLuster 5 = Vals Is Here Surprise That Special Someone Now\n",
      "\n",
      "You can reach Us On 0205414305or WhatsApp 0555171905 \n",
      "For The Bes... https://t.co/E9CSZvxFCT\n",
      "\n",
      "CLuster 6 = Global Shipping has Been Hit by the Coronavirus\n",
      "\n",
      "Now Goods are Getting Stranded\n",
      "\n",
      "by @hannaziady\n",
      "via @CNNBusiness... https://t.co/NO1WbANzDh\n",
      "\n",
      "CLuster 7 = A 37-year-old woman has become the 15th person in Australia diagnosed with coronavirus - the fifth in Queensland.... https://t.co/UtfPvHwjvR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets['cluster'] = p\n",
    "for c in np.unique(p):\n",
    "    print('CLuster {} = {}'.format(c, tweets[tweets['cluster']==c]['txt'].iloc[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
