{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from src.databases import Postgresql \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFECV \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando os dados!!!\n",
      "Conexão com Postgresql fechada\n"
     ]
    }
   ],
   "source": [
    "# trazer o dataset com as viariaveis dummy do banco de dados\n",
    "query = \"\"\" SELECT * FROM dataset_final;\"\"\"\n",
    "bd = Postgresql(user='postgres' , password='bruno22#' , host= 'localhost', port= '5432', database = 'brunods')\n",
    "dataset= bd.retrieve_data(query=query)\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "dataset.set_index('sku', inplace=True)\n",
    "dataset = dataset.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>vinicola</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>safra</th>\n",
       "      <th>temperatura</th>\n",
       "      <th>potencial_guarda</th>\n",
       "      <th>cat_safra</th>\n",
       "      <th>teor_cat</th>\n",
       "      <th>...</th>\n",
       "      <th>inox</th>\n",
       "      <th>metodo_tradicional</th>\n",
       "      <th>garrafas</th>\n",
       "      <th>concreto</th>\n",
       "      <th>gustativo</th>\n",
       "      <th>visual</th>\n",
       "      <th>ofativo</th>\n",
       "      <th>comments_label</th>\n",
       "      <th>uva</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sku</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12390</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12733</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12734</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12813</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tipo  country  region  vinicola  classificacao  safra  temperatura  \\\n",
       "sku                                                                         \n",
       "11549     0        9      96       116              3      1            2   \n",
       "12390     0        8      45        10              2     16            2   \n",
       "12733     4        6      81        94              2     15            0   \n",
       "12734     0        4     102        37              2     17            1   \n",
       "12813     4        8      76        44              2      8            0   \n",
       "\n",
       "       potencial_guarda  cat_safra  teor_cat  ...  inox  metodo_tradicional  \\\n",
       "sku                                           ...                             \n",
       "11549                 1          0         1  ...     0                   0   \n",
       "12390                 0          0         1  ...     1                   0   \n",
       "12733                 0          0         0  ...     0                   0   \n",
       "12734                 0          0         2  ...     1                   0   \n",
       "12813                 1          0         0  ...     0                   0   \n",
       "\n",
       "       garrafas  concreto  gustativo  visual  ofativo  comments_label  uva  \\\n",
       "sku                                                                          \n",
       "11549         0         0          0       0        4               0   35   \n",
       "12390         0         0          0       0        4               0   85   \n",
       "12733         0         0          5       2        4               0   95   \n",
       "12734         0         0          0       0        4               0   24   \n",
       "12813         0         0          5       2        2               0   58   \n",
       "\n",
       "       rating  \n",
       "sku            \n",
       "11549       0  \n",
       "12390       0  \n",
       "12733       0  \n",
       "12734       0  \n",
       "12813       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanciamento realizado:  [(0, 334), (1, 334)]\n"
     ]
    }
   ],
   "source": [
    "#divisão dos dados\n",
    "X= dataset.drop('rating', axis=1)\n",
    "y= dataset['rating']\n",
    "\n",
    "#Divisão entre treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X,y,test_size = 0.2, random_state=104)\n",
    "\n",
    "# Balanciando o dataset \n",
    "x, y = SMOTE().fit_resample(X_treino, y_treino)\n",
    "print('Balanciamento realizado: ', sorted(Counter(y).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 20)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 20)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi2/f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia com <function chi2 at 0x7f5b4c6cfdc0>: 0.648\n",
      "Acuracia com <function f_classif at 0x7f5b4c6cfa60>: 0.615\n"
     ]
    }
   ],
   "source": [
    "# Testando chi2 ou f_classif\n",
    "\n",
    "def chi2_anova(tec1, tec2):\n",
    "    tecnicas = [tec1, tec2]\n",
    "\n",
    "    for item in tecnicas:\n",
    "        model_select = make_pipeline(\n",
    "                    SelectKBest(item, k=5), MinMaxScaler(), LogisticRegression()\n",
    "            )\n",
    "        model_select.fit(x, y)\n",
    "        print('Acuracia com {}: {:.3f}'.format(item, model_select.score(X_teste, y_teste)))\n",
    "\n",
    "chi2_anova(chi2, f_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia de : 0.4642857142857143\n",
      "Acuracia de : 0.463855421686747\n",
      "Acuracia de : 0.463855421686747\n",
      "A media da acuracia de cada round é 0.46399885255306944\n"
     ]
    }
   ],
   "source": [
    "#Regressão Logistica\n",
    "rounds = [1,2,3]\n",
    "acc = []\n",
    "for r in rounds:\n",
    "    clf = RandomForestClassifier()\n",
    "    selector = RFECV(estimator=clf, cv=5).fit(x,y)\n",
    "    index = selector.get_support(indices=True)\n",
    "    x_ = x.iloc[:,index]\n",
    "    X_teste_ =  X_teste.iloc[:,index]\n",
    "\n",
    "    model_select = make_pipeline(\n",
    "        MinMaxScaler(), ExtraTreesClassifier()\n",
    "    )\n",
    "\n",
    "    model_select.fit(x_, y)\n",
    "    p=model_select.predict(X_teste_)\n",
    "    acc.append(roc_auc_score(p, y_teste))\n",
    "    print(f'Acuracia de : {roc_auc_score(p, y_teste)}')\n",
    "print(f'A media da acuracia de cada round é {np.mean(acc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia com a quantidade k de 1: 0.505\n",
      "Acuracia com a quantidade k de 2: 0.516\n",
      "Acuracia com a quantidade k de 3: 0.451\n",
      "Acuracia com a quantidade k de 4: 0.516\n",
      "Acuracia com a quantidade k de 5: 0.648\n",
      "Acuracia com a quantidade k de 6: 0.659\n",
      "Acuracia com a quantidade k de 7: 0.659\n",
      "Acuracia com a quantidade k de 8: 0.637\n",
      "Acuracia com a quantidade k de 9: 0.670\n",
      "Acuracia com a quantidade k de 10: 0.703\n",
      "Acuracia com a quantidade k de 11: 0.703\n",
      "Acuracia com a quantidade k de 12: 0.692\n",
      "Acuracia com a quantidade k de 13: 0.714\n",
      "Acuracia com a quantidade k de 14: 0.714\n",
      "Acuracia com a quantidade k de 15: 0.714\n",
      "Acuracia com a quantidade k de 16: 0.714\n",
      "Acuracia com a quantidade k de 17: 0.736\n",
      "Acuracia com a quantidade k de 18: 0.725\n",
      "Acuracia com a quantidade k de 19: 0.725\n",
      "Acuracia com a quantidade k de 20: 0.725\n"
     ]
    }
   ],
   "source": [
    "# Testando quantidade de k - Foward Elimination\n",
    "#Regresão Logistica\n",
    "\n",
    "def n_k_rl(method, ks, model):\n",
    "    num_k= ks\n",
    "    for item in num_k:\n",
    "\n",
    "        model_select = make_pipeline(\n",
    "                SelectKBest(method, k=item), MinMaxScaler(),model()\n",
    "        )\n",
    "        model_select.fit(x, y)\n",
    "        print('Acuracia com a quantidade k de {}: {:.3f}'.format(item, model_select.score(X_teste, y_teste)))\n",
    "\n",
    "n_k_rl(chi2, ks=list(range(1,21)), model=LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia com a quantidade k de 1: 0.769\n",
      "Acuracia com a quantidade k de 2: 0.813\n",
      "Acuracia com a quantidade k de 3: 0.813\n",
      "Acuracia com a quantidade k de 4: 0.802\n",
      "Acuracia com a quantidade k de 5: 0.769\n",
      "Acuracia com a quantidade k de 6: 0.758\n",
      "Acuracia com a quantidade k de 7: 0.791\n",
      "Acuracia com a quantidade k de 8: 0.813\n",
      "Acuracia com a quantidade k de 9: 0.802\n",
      "Acuracia com a quantidade k de 10: 0.857\n",
      "Acuracia com a quantidade k de 11: 0.868\n",
      "Acuracia com a quantidade k de 12: 0.824\n",
      "Acuracia com a quantidade k de 13: 0.813\n",
      "Acuracia com a quantidade k de 14: 0.846\n",
      "Acuracia com a quantidade k de 15: 0.857\n",
      "Acuracia com a quantidade k de 16: 0.835\n",
      "Acuracia com a quantidade k de 17: 0.835\n",
      "Acuracia com a quantidade k de 18: 0.857\n",
      "Acuracia com a quantidade k de 19: 0.846\n",
      "Acuracia com a quantidade k de 20: 0.857\n"
     ]
    }
   ],
   "source": [
    "#ExtraTreesClassifier\n",
    "def n_k_et(method, ks, model):\n",
    "    num_k= ks\n",
    "    for item in num_k:\n",
    "\n",
    "        model_select = make_pipeline(\n",
    "                SelectKBest(method, k=item), MinMaxScaler(),model()\n",
    "        )\n",
    "        model_select.fit(x, y)\n",
    "        print('Acuracia com a quantidade k de {}: {:.3f}'.format(item, model_select.score(X_teste, y_teste)))\n",
    "\n",
    "n_k_et(chi2, ks=list(range(1,21)), model=ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia com a quantidade k de 1: 0.495\n",
      "Acuracia com a quantidade k de 2: 0.330\n",
      "Acuracia com a quantidade k de 3: 0.418\n",
      "Acuracia com a quantidade k de 4: 0.560\n",
      "Acuracia com a quantidade k de 5: 0.670\n",
      "Acuracia com a quantidade k de 6: 0.692\n",
      "Acuracia com a quantidade k de 7: 0.703\n",
      "Acuracia com a quantidade k de 8: 0.824\n",
      "Acuracia com a quantidade k de 9: 0.813\n",
      "Acuracia com a quantidade k de 10: 0.846\n",
      "Acuracia com a quantidade k de 11: 0.835\n",
      "Acuracia com a quantidade k de 12: 0.835\n",
      "Acuracia com a quantidade k de 13: 0.813\n",
      "Acuracia com a quantidade k de 14: 0.868\n",
      "Acuracia com a quantidade k de 15: 0.857\n",
      "Acuracia com a quantidade k de 16: 0.857\n",
      "Acuracia com a quantidade k de 17: 0.857\n",
      "Acuracia com a quantidade k de 18: 0.857\n",
      "Acuracia com a quantidade k de 19: 0.857\n",
      "Acuracia com a quantidade k de 20: 0.835\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "\n",
    "def n_k_svc(method, ks, model):\n",
    "    num_k= ks\n",
    "    for item in num_k:\n",
    "\n",
    "        model_select = make_pipeline(\n",
    "                SelectKBest(method, k=item),MinMaxScaler(),model(random_state=0)\n",
    "        )\n",
    "        model_select.fit(x, y)\n",
    "        print('Acuracia com a quantidade k de {}: {:.3f}'.format(item, model_select.score(X_teste, y_teste)))\n",
    "\n",
    "n_k_svc(chi2, ks=list(range(1,21)), model = SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia com a quantidade k de 1: 0.725\n",
      "Acuracia com a quantidade k de 2: 0.769\n",
      "Acuracia com a quantidade k de 3: 0.780\n",
      "Acuracia com a quantidade k de 4: 0.791\n",
      "Acuracia com a quantidade k de 5: 0.725\n",
      "Acuracia com a quantidade k de 6: 0.769\n",
      "Acuracia com a quantidade k de 7: 0.802\n",
      "Acuracia com a quantidade k de 8: 0.824\n",
      "Acuracia com a quantidade k de 9: 0.802\n",
      "Acuracia com a quantidade k de 10: 0.835\n",
      "Acuracia com a quantidade k de 11: 0.868\n",
      "Acuracia com a quantidade k de 12: 0.857\n",
      "Acuracia com a quantidade k de 13: 0.846\n",
      "Acuracia com a quantidade k de 14: 0.846\n",
      "Acuracia com a quantidade k de 15: 0.868\n",
      "Acuracia com a quantidade k de 16: 0.857\n",
      "Acuracia com a quantidade k de 17: 0.857\n",
      "Acuracia com a quantidade k de 18: 0.846\n",
      "Acuracia com a quantidade k de 19: 0.868\n",
      "Acuracia com a quantidade k de 20: 0.857\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "def n_k_rf(method, ks, model):\n",
    "    num_k= ks\n",
    "    for item in num_k:\n",
    "\n",
    "        model_select = make_pipeline(\n",
    "                SelectKBest(method, k=item),model(random_state=0)\n",
    "        )\n",
    "        model_select.fit(x, y)\n",
    "        print('Acuracia com a quantidade k de {}: {:.3f}'.format(item, model_select.score(X_teste, y_teste)))\n",
    "\n",
    "n_k_rf(chi2, ks=list(range(1,21)), model=RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices da variavies são : [ 0  1  3  4  5  6  7  9 11 12 13 14 15 16 17 19]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo</th>\n",
       "      <th>country</th>\n",
       "      <th>vinicola</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>safra</th>\n",
       "      <th>temperatura</th>\n",
       "      <th>potencial_guarda</th>\n",
       "      <th>teor_cat</th>\n",
       "      <th>inox</th>\n",
       "      <th>metodo_tradicional</th>\n",
       "      <th>garrafas</th>\n",
       "      <th>concreto</th>\n",
       "      <th>gustativo</th>\n",
       "      <th>visual</th>\n",
       "      <th>ofativo</th>\n",
       "      <th>uva</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sku</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12390</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12733</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12734</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12813</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tipo  country  vinicola  classificacao  safra  temperatura  \\\n",
       "sku                                                                 \n",
       "11549     0        9       116              3      1            2   \n",
       "12390     0        8        10              2     16            2   \n",
       "12733     4        6        94              2     15            0   \n",
       "12734     0        4        37              2     17            1   \n",
       "12813     4        8        44              2      8            0   \n",
       "\n",
       "       potencial_guarda  teor_cat  inox  metodo_tradicional  garrafas  \\\n",
       "sku                                                                     \n",
       "11549                 1         1     0                   0         0   \n",
       "12390                 0         1     1                   0         0   \n",
       "12733                 0         0     0                   0         0   \n",
       "12734                 0         2     1                   0         0   \n",
       "12813                 1         0     0                   0         0   \n",
       "\n",
       "       concreto  gustativo  visual  ofativo  uva  \n",
       "sku                                               \n",
       "11549         0          0       0        4   35  \n",
       "12390         0          0       0        4   85  \n",
       "12733         0          5       2        4   95  \n",
       "12734         0          0       0        4   24  \n",
       "12813         0          5       2        2   58  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_best = SelectKBest(score_func=f_classif, k=16)\n",
    "selected  = k_best.fit(X_treino,y_treino)\n",
    "index = selected.get_support(indices=True)\n",
    "\n",
    "print(f'Indices da variavies são : {index}')\n",
    "\n",
    "#features\n",
    "dados = dataset.iloc[:,index]\n",
    "\n",
    "print('\\n')\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando o efeito do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "#dataset_pca = dataset.copy()\n",
    "#X= dataset_pca.drop('rating', axis=1)\n",
    "#y= dataset_pca['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Normalizados\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 32.83\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.5745791245791246\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 43.73\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.6569023569023568\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 53.53\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7393939393939394\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 62.02\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7462962962962963\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 68.9\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7462962962962963\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 75.23\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7462962962962963\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 80.3\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7462962962962963\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 84.61\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7538720538720538\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 87.95\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7388888888888889\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 90.72\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7462962962962963\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 93.28\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7462962962962963\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 95.48\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7538720538720538\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 97.22\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7388888888888889\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 98.56\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7464646464646464\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.12\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7762626262626262\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.6\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7762626262626262\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.86\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7762626262626262\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7762626262626262\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7762626262626262\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7762626262626262\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Regressão Logistica 11 componentes\n",
    "# Normalização\n",
    "scl = MinMaxScaler()\n",
    "scl_x = scl.fit_transform(x)\n",
    "print(\"Dados Normalizados\")\n",
    "\n",
    "for num in list(range(1,21)):\n",
    "    \n",
    "    # Redução da Dimensionalidade\n",
    "    pca = PCA(n_components=num)\n",
    "    x_fit = pca.fit(scl_x)\n",
    "    x_red = pca.fit_transform(scl_x)\n",
    "    print(\"Redução de Dimensionalidade concluída\")\n",
    "    print(f'Variância capturada de {round(x_fit.explained_variance_ratio_.sum() * 100, 2)}')\n",
    "\n",
    "    # Variáveis de Treino e Teste\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(x_red, y, test_size=0.2, random_state=42)\n",
    "    print(\"Divisão entre dados de treino e teste concluída\")\n",
    "    \n",
    "    #Cross Validação\n",
    "    reg = LogisticRegression().fit(X_treino,y_treino)\n",
    "    print(np.mean(cross_val_score(reg, X_teste, y_teste, cv=3)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Normalizados\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 32.83\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.664141414141414\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 43.73\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.709090909090909\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 53.53\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8203703703703704\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 62.02\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8203703703703704\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 68.9\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.842929292929293\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 75.23\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.857912457912458\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 80.3\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8353535353535353\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 84.61\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.828114478114478\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 87.95\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8506734006734007\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 90.72\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.842929292929293\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 93.28\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8503367003367003\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 95.48\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8279461279461279\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 97.22\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8207070707070706\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 98.56\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8279461279461279\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.12\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.857912457912458\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.6\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.857912457912458\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.86\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8503367003367003\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8508417508417508\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8580808080808081\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8434343434343434\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extra Trees 8 componentes\n",
    "# Normalização\n",
    "scl = MinMaxScaler()\n",
    "scl_x = scl.fit_transform(x)\n",
    "print(\"Dados Normalizados\")\n",
    "\n",
    "for num in list(range(1,21)):\n",
    "    # Redução da Dimensionalidade\n",
    "    pca = PCA(n_components=num)\n",
    "    x_fit = pca.fit(scl_x)\n",
    "    x_red = pca.fit_transform(scl_x)\n",
    "    print(\"Redução de Dimensionalidade concluída\")\n",
    "    print(f'Variância capturada de {round(x_fit.explained_variance_ratio_.sum() * 100, 2)}')\n",
    "\n",
    "    # Variáveis de Treino e Teste\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(x_red, y, test_size=0.2, random_state=42)\n",
    "    print(\"Divisão entre dados de treino e teste concluída\")\n",
    "    \n",
    "    #Cross Validação\n",
    "    reg = ExtraTreesClassifier().fit(X_treino,y_treino)\n",
    "    print(np.mean(cross_val_score(reg, X_teste, y_teste, cv=3)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Normalizados\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 32.83\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.6343434343434343\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 43.73\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7018518518518518\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 53.53\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7390572390572391\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 62.02\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7836700336700337\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 68.9\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7686868686868685\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 75.23\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7609427609427609\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 80.3\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7685185185185185\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 84.61\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.776094276094276\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 87.95\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7984848484848485\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 90.72\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 93.28\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 95.48\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 97.22\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 98.56\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7759259259259258\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.12\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7759259259259258\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.6\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.86\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7833333333333333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svc \n",
    "# Normalização\n",
    "scl = MinMaxScaler()\n",
    "scl_x = scl.fit_transform(x)\n",
    "print(\"Dados Normalizados\")\n",
    "\n",
    "for num in list(range(1,21)):\n",
    "    # Redução da Dimensionalidade\n",
    "    pca = PCA(n_components=num)\n",
    "    x_fit = pca.fit(scl_x)\n",
    "    x_red = pca.fit_transform(scl_x)\n",
    "    print(\"Redução de Dimensionalidade concluída\")\n",
    "    print(f'Variância capturada de {round(x_fit.explained_variance_ratio_.sum() * 100, 2)}')\n",
    "\n",
    "    # Variáveis de Treino e Teste\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(x_red, y, test_size=0.2, random_state=42)\n",
    "    print(\"Divisão entre dados de treino e teste concluída\")\n",
    "    \n",
    "    #Cross Validação\n",
    "    reg = SVC().fit(X_treino,y_treino)\n",
    "    print(np.mean(cross_val_score(reg, X_teste, y_teste, cv=3)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Normalizados\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 32.83\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.664141414141414\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 43.73\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7164983164983165\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 53.53\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8506734006734007\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 62.02\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.812962962962963\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 68.9\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.842929292929293\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 75.23\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8505050505050505\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 80.3\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.7981481481481482\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 84.61\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8057239057239057\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 87.95\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8279461279461279\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 90.72\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8205387205387206\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 93.28\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8131313131313131\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 95.48\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8134680134680136\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 97.22\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8207070707070706\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 98.56\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8055555555555557\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.12\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8505050505050505\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.6\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8203703703703704\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.86\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8134680134680136\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8282828282828283\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.8208754208754209\n",
      "\n",
      "\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 100.0\n",
      "Divisão entre dados de treino e teste concluída\n",
      "0.842929292929293\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "# Normalização\n",
    "scl = MinMaxScaler()\n",
    "scl_x = scl.fit_transform(x)\n",
    "print(\"Dados Normalizados\")\n",
    "\n",
    "for num in list(range(1,21)):\n",
    "    # Redução da Dimensionalidade\n",
    "    pca = PCA(n_components=num)\n",
    "    x_fit = pca.fit(scl_x)\n",
    "    x_red = pca.fit_transform(scl_x)\n",
    "    print(\"Redução de Dimensionalidade concluída\")\n",
    "    print(f'Variância capturada de {round(x_fit.explained_variance_ratio_.sum() * 100, 2)}')\n",
    "\n",
    "    # Variáveis de Treino e Teste\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(x_red, y, test_size=0.2, random_state=42)\n",
    "    print(\"Divisão entre dados de treino e teste concluída\")\n",
    "    \n",
    "    #Cross Validação\n",
    "    reg = RandomForestClassifier().fit(X_treino,y_treino)\n",
    "    print(np.mean(cross_val_score(reg, X_teste, y_teste, cv=3)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv-ds-38': conda)",
   "language": "python",
   "name": "python38264bitvenvds38conda3f45df97c22b4399879b2f46054e6fe7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
