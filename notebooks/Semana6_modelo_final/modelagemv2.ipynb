{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from collections import Counter\n",
    "from src.databases import Postgresql \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_RF(X,y,n_iter):\n",
    "    \n",
    "    print('> Procurando os melhores parametros...')\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 500, stop = 2000, num = 10)]\n",
    "    max_features = ['auto', 'sqrt','log2']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    criterion = ['gini','entropy']\n",
    "    min_samples_split = [2, 5, 10, 12]\n",
    "    min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    random_grid = {'max_features':max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_sample_split': min_sample_split,\n",
    "                   'min_samples_leaf': min_sample_leaf,\n",
    "                   'criterion': criterion,\n",
    "                   'bootstrap': bootstrap}\n",
    "    \n",
    "    random_state = 2\n",
    "    rfc = RandomForestClassifier(n_jobs=-1)\n",
    "    rf_random = RandomizedSearchCV(estimator=rfc, param_distributions=random_grid, \n",
    "                                   n_iter=n_iter, cv=5, verbose=0, random_state=random_state, \n",
    "                                   n_jobs=-1, scoring={'AUC':'roc_auc'},refit='AUC')\n",
    "\n",
    "    # Fit the random search model\n",
    "    print('> Fitting Modelo...')\n",
    "    rf_random.fit(X, y)\n",
    "  \n",
    "    return rf_random.best_estimator_, rf_random.cv_results_, rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando os dados!!!\n",
      "Conexão com Postgresql fechada\n",
      "Balanciamento realizado:  [('0', 333), ('1', 333)]\n",
      "ROCAUC com crossvalidação de 0.9070774114421759\n",
      "ROCAUC em dados de teste de 0.48214285714285715\n"
     ]
    }
   ],
   "source": [
    "# Processo de treinamento.\n",
    "\n",
    "query = \"\"\" SELECT * FROM dataset_final;\"\"\"\n",
    "bd = Postgresql(user='postgres' , password='bruno22#' , host= 'localhost', port= '5432', database = 'brunods')\n",
    "datasetv1= bd.retrieve_data(query=query)\n",
    "datasetv1.set_index('sku', inplace=True)\n",
    "            \n",
    "\n",
    "    \n",
    "#divisão dos dados\n",
    "X= datasetv1.drop('rating', axis=1)\n",
    "Y= datasetv1['rating']\n",
    "\n",
    "\n",
    "k_best = SelectKBest(score_func=f_classif, k=18)\n",
    "selected  = k_best.fit(X,Y)\n",
    "index = selected.get_support(indices=True)\n",
    "\n",
    "\n",
    "X1 = X.iloc[:,index]\n",
    "Y1 = Y\n",
    "\n",
    "\n",
    "#Divisão entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1,Y1,test_size = 0.2, random_state=0)\n",
    "\n",
    "# Balanciando o dataset\n",
    "x1, y1 = SMOTE().fit_resample(X_train, y_train)\n",
    "print('Balanciamento realizado: ', sorted(Counter(y1).items()))\n",
    "\n",
    "#trained_model, results, params=random_RF(x1,y1,10)  \n",
    "\n",
    "\n",
    "#trained_model = LogisticRegression(solver = 'liblinear', penalty = 'l1', C = 0.14)  #0.14\n",
    "trained_model = RandomForestClassifier(n_estimators = 5000, max_features = 'sqrt', criterion = 'entropy', \n",
    "                                        bootstrap = True, min_samples_split = 10 , max_depth = 50 , min_samples_leaf= 10)\n",
    "\n",
    "\n",
    "resultado = []\n",
    "kf = RepeatedKFold(n_splits = 2, n_repeats=10, random_state=1)\n",
    "\n",
    "for linhas_treino, linhas_valid in kf.split(x1):\n",
    "\n",
    "    X_treino, X_valid = x1.iloc[linhas_treino], x1.iloc[linhas_valid]\n",
    "    y_treino, y_valid = y1.iloc[linhas_treino], y1.iloc[linhas_valid]\n",
    "\n",
    "\n",
    "    trained_model.fit(X_treino,y_treino)\n",
    "    p= trained_model.predict(X_valid)\n",
    "    acc = np.mean(y_valid==p)\n",
    "    resultado.append(acc)\n",
    "print(f'ROCAUC com crossvalidação de {roc_auc_score(y_valid,p)}')\n",
    "\n",
    "#Em dados de teste\n",
    "trained_model.fit(x1,y1)\n",
    "p1 = trained_model.predict(X_test)\n",
    "print(f'ROCAUC em dados de teste de {roc_auc_score(y_test,p1)}')\n",
    "\n",
    "import pickle\n",
    "file = 'model_v4.sav'\n",
    "pickle.dump(trained_model, open(file,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94        89\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        92\n",
      "   macro avg       0.48      0.46      0.47        92\n",
      "weighted avg       0.93      0.88      0.91        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(p1,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>classe_0</th>\n",
       "      <th>classe_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [real, classe_0, classe_1]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = trained_model.predict_proba(X_test)\n",
    "proba\n",
    "\n",
    "data = np.column_stack((y_test, proba))\n",
    "df = pd.DataFrame(data, columns = ['real', 'classe_0', 'classe_1'])\n",
    "df.loc[df['classe_1'] > 0.9,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis\n",
    "import pickle\n",
    "potencial_de_guarda = int(input('Potencial de Guarda:'))\n",
    "inox = int(input('Inox:'))\n",
    "franca = int(input('França:'))\n",
    "chile = int(input('Chile:'))\n",
    "chardonnay = int(input('Chardonnay:'))\n",
    "\n",
    "#transformar as variaveis em DF\n",
    "data = np.column_stack((potencial_de_guarda,inox, franca, chile, chardonnay))\n",
    "df = pd.DataFrame(data, columns = ['potencial_de_guarda','inox', 'franca', 'chile', 'chardonnay'])\n",
    "\n",
    "#Load do modelo\n",
    "model = pickle.load(open('model_v1.sav','rb'))\n",
    "result = model.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Rating com mais categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final\n",
    "query = \"\"\" SELECT * FROM dataset_finalv1;\"\"\"\n",
    "bd = Postgresql(user='postgres' , password='bruno22#' , host= 'localhost', port= '5432', database = 'brunods')\n",
    "datasetv1= bd.retrieve_data(query=query)\n",
    "\n",
    "#rating\n",
    "query1 = \"\"\"SELECT sku, CASE WHEN RATING = 3.5 THEN 3\n",
    "            WHEN RATING = 1.5 THEN 1\n",
    "            WHEN RATING = 2.5 THEN 2\n",
    "            WHEN RATING = 4.5 THEN 4\n",
    "            WHEN RATING = 1 THEN 1\n",
    "            WHEN RATING = 2 THEN 2\n",
    "            WHEN RATING = 3 THEN 3\n",
    "            WHEN RATING = 4 THEN 4\n",
    "            WHEN RATING = 5 THEN 5\n",
    "        END AS RATING\n",
    "FROM rating;\"\"\"\n",
    "bd = Postgresql(user='postgres' , password='bruno22#' , host= 'localhost', port= '5432', database = 'brunods')\n",
    "rating= bd.retrieve_data(query=query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating[rating.sku == 12815]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_len(x):\n",
    "    if len(x)!=6:\n",
    "        return x\n",
    "    else:\n",
    "        return 'filter'\n",
    "\n",
    "rating['mask'] = rating['sku'].apply(check_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_new = rating[rating['mask'] != 'filter']\n",
    "rating_new['sku'] = rating_new.sku.astype('int64')\n",
    "rating_new.drop('mask', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(datasetv1,rating_new, left_on='sku', right_on='sku', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv-ds-38': conda)",
   "language": "python",
   "name": "python38264bitvenvds38conda3f45df97c22b4399879b2f46054e6fe7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
